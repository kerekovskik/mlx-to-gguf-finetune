{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone HF Repo for TinyLlama Model\n",
    "# !git clone https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlx-lm in ./convert_to_mlx_venv/lib/python3.10/site-packages (from -r ./requirements_convert_to_mlx.txt (line 1)) (0.0.8)\n",
      "Collecting ai2-olmo\n",
      "  Using cached ai2_olmo-0.2.4-py3-none-any.whl (113 kB)\n",
      "Requirement already satisfied: transformers>=4.37.0 in ./convert_to_mlx_venv/lib/python3.10/site-packages (from mlx-lm->-r ./requirements_convert_to_mlx.txt (line 1)) (4.37.2)\n",
      "Requirement already satisfied: protobuf in ./convert_to_mlx_venv/lib/python3.10/site-packages (from mlx-lm->-r ./requirements_convert_to_mlx.txt (line 1)) (4.25.2)\n",
      "Requirement already satisfied: mlx in ./convert_to_mlx_venv/lib/python3.10/site-packages (from mlx-lm->-r ./requirements_convert_to_mlx.txt (line 1)) (0.1.0)\n",
      "Requirement already satisfied: numpy in ./convert_to_mlx_venv/lib/python3.10/site-packages (from mlx-lm->-r ./requirements_convert_to_mlx.txt (line 1)) (1.26.4)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.34.36-py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m869.7 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting rich\n",
      "  Using cached rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "Collecting google-cloud-storage\n",
      "  Using cached google_cloud_storage-2.14.0-py2.py3-none-any.whl (121 kB)\n",
      "Requirement already satisfied: packaging in ./convert_to_mlx_venv/lib/python3.10/site-packages (from ai2-olmo->-r ./requirements_convert_to_mlx.txt (line 2)) (23.2)\n",
      "Collecting omegaconf\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Collecting cached-path\n",
      "  Using cached cached_path-1.5.1-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: tokenizers in ./convert_to_mlx_venv/lib/python3.10/site-packages (from ai2-olmo->-r ./requirements_convert_to_mlx.txt (line 2)) (0.15.1)\n",
      "Collecting torch<2.2,>=2.0\n",
      "  Using cached torch-2.1.2-cp310-none-macosx_11_0_arm64.whl (59.6 MB)\n",
      "Requirement already satisfied: fsspec in ./convert_to_mlx_venv/lib/python3.10/site-packages (from torch<2.2,>=2.0->ai2-olmo->-r ./requirements_convert_to_mlx.txt (line 2)) (2024.2.0)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Requirement already satisfied: typing-extensions in ./convert_to_mlx_venv/lib/python3.10/site-packages (from torch<2.2,>=2.0->ai2-olmo->-r ./requirements_convert_to_mlx.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: filelock in ./convert_to_mlx_venv/lib/python3.10/site-packages (from torch<2.2,>=2.0->ai2-olmo->-r ./requirements_convert_to_mlx.txt (line 2)) (3.13.1)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./convert_to_mlx_venv/lib/python3.10/site-packages (from transformers>=4.37.0->mlx-lm->-r ./requirements_convert_to_mlx.txt (line 1)) (4.66.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./convert_to_mlx_venv/lib/python3.10/site-packages (from transformers>=4.37.0->mlx-lm->-r ./requirements_convert_to_mlx.txt (line 1)) (2023.12.25)\n",
      "Requirement already satisfied: requests in ./convert_to_mlx_venv/lib/python3.10/site-packages (from transformers>=4.37.0->mlx-lm->-r ./requirements_convert_to_mlx.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./convert_to_mlx_venv/lib/python3.10/site-packages (from transformers>=4.37.0->mlx-lm->-r ./requirements_convert_to_mlx.txt (line 1)) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./convert_to_mlx_venv/lib/python3.10/site-packages (from transformers>=4.37.0->mlx-lm->-r ./requirements_convert_to_mlx.txt (line 1)) (0.20.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./convert_to_mlx_venv/lib/python3.10/site-packages (from transformers>=4.37.0->mlx-lm->-r ./requirements_convert_to_mlx.txt (line 1)) (6.0.1)\n",
      "Collecting botocore<1.35.0,>=1.34.36\n",
      "  Downloading botocore-1.34.36-py3-none-any.whl (11.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0\n",
      "  Using cached s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3\n",
      "  Using cached huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Using cached google_api_core-2.16.2-py3-none-any.whl (135 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Using cached google_crc32c-1.5.0-cp310-cp310-macosx_10_9_universal2.whl (32 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0\n",
      "  Using cached google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Collecting google-auth<3.0dev,>=2.23.3\n",
      "  Using cached google_auth-2.27.0-py2.py3-none-any.whl (186 kB)\n",
      "Collecting google-resumable-media>=2.6.0\n",
      "  Using cached google_resumable_media-2.7.0-py2.py3-none-any.whl (80 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./convert_to_mlx_venv/lib/python3.10/site-packages (from rich->ai2-olmo->-r ./requirements_convert_to_mlx.txt (line 2)) (2.17.2)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./convert_to_mlx_venv/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.36->boto3->ai2-olmo->-r ./requirements_convert_to_mlx.txt (line 2)) (2.8.2)\n",
      "Collecting urllib3<2.1,>=1.25.4\n",
      "  Using cached urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
      "  Using cached googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./convert_to_mlx_venv/lib/python3.10/site-packages (from requests->transformers>=4.37.0->mlx-lm->-r ./requirements_convert_to_mlx.txt (line 1)) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./convert_to_mlx_venv/lib/python3.10/site-packages (from requests->transformers>=4.37.0->mlx-lm->-r ./requirements_convert_to_mlx.txt (line 1)) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./convert_to_mlx_venv/lib/python3.10/site-packages (from requests->transformers>=4.37.0->mlx-lm->-r ./requirements_convert_to_mlx.txt (line 1)) (3.3.2)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-macosx_10_9_universal2.whl (18 kB)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./convert_to_mlx_venv/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.36->boto3->ai2-olmo->-r ./requirements_convert_to_mlx.txt (line 2)) (1.16.0)\n",
      "Installing collected packages: mpmath, antlr4-python3-runtime, urllib3, sympy, pyasn1, omegaconf, networkx, mdurl, MarkupSafe, jmespath, googleapis-common-protos, google-crc32c, filelock, cachetools, rsa, pyasn1-modules, markdown-it-py, jinja2, google-resumable-media, botocore, torch, s3transfer, rich, huggingface-hub, google-auth, google-api-core, boto3, google-cloud-core, google-cloud-storage, cached-path, ai2-olmo\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.0\n",
      "    Uninstalling urllib3-2.2.0:\n",
      "      Successfully uninstalled urllib3-2.2.0\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.13.1\n",
      "    Uninstalling filelock-3.13.1:\n",
      "      Successfully uninstalled filelock-3.13.1\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.20.3\n",
      "    Uninstalling huggingface-hub-0.20.3:\n",
      "      Successfully uninstalled huggingface-hub-0.20.3\n",
      "Successfully installed MarkupSafe-2.1.5 ai2-olmo-0.2.4 antlr4-python3-runtime-4.9.3 boto3-1.34.36 botocore-1.34.36 cached-path-1.5.1 cachetools-5.3.2 filelock-3.12.4 google-api-core-2.16.2 google-auth-2.27.0 google-cloud-core-2.4.1 google-cloud-storage-2.14.0 google-crc32c-1.5.0 google-resumable-media-2.7.0 googleapis-common-protos-1.62.0 huggingface-hub-0.19.4 jinja2-3.1.3 jmespath-1.0.1 markdown-it-py-3.0.0 mdurl-0.1.2 mpmath-1.3.0 networkx-3.2.1 omegaconf-2.3.0 pyasn1-0.5.1 pyasn1-modules-0.3.0 rich-13.7.0 rsa-4.9 s3transfer-0.10.0 sympy-1.12 torch-2.1.2 urllib3-2.0.7\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install mlx-lm\n",
    "!python3 -m pip install -r ./requirements_convert_to_mlx.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading\n"
     ]
    }
   ],
   "source": [
    "import mlx_lm\n",
    "\n",
    "tinyllama_sf_path = \"./TinyLlama-1.1B-Chat-v1.0\"\n",
    "tinyllama_mlx_path = \"./TinyLlama-1.1B-Chat-v1.0-MLX\"\n",
    "mlx_lm.convert(\n",
    "    hf_path=tinyllama_sf_path,\n",
    "    mlx_path= tinyllama_mlx_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convert_to_mlx_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
